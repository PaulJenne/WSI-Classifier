import tensorflow as tf
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt #um Bilder im output anzuschauen
import matplotlib.image as mpimg 

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D
from tensorflow.keras import regularizers, optimizers
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import img_to_array

# ----------------------DATEN----------------------
def append_ext(fn):
    return fn + ".tif"  # Bildformat ist .tif

# Einlesen der csv-Dateien als String
traindf = pd.read_csv('/Users/pauljenne/Downloads/train_labels.csv', dtype=str)
testdf = pd.read_csv('/Users/pauljenne/Downloads/sample_submission.csv', dtype=str)

# AnhÃ¤ngen der Dateiendung an die ID
traindf["id"] = traindf["id"].apply(append_ext)
testdf["id"] = testdf["id"].apply(append_ext)

# ----------------------IMAGE AUGMENTATION----------------------


# ----------------------DATENGENERATOR----------------------
# ImageDataGenerator with rescaling and validation split (25% of the data will go to the validation set)
datagen = ImageDataGenerator(
    rescale=1./255.,
    validation_split=0.25,
    rotation_range=20,  # Rotate the image randomly within the range of -20 to +20 degrees
    width_shift_range=0.1,  # Shift the width of the image randomly within the range of -0.1 to +0.1
    height_shift_range=0.1,  # Shift the height of the image randomly within the range of -0.1 to +0.1
    shear_range=0.2,  # Apply shear transformation randomly within the range of -0.2 to +0.2
    zoom_range=0.2,  # Zoom the image randomly within the range of 0.8 to 1.2
    horizontal_flip=True,  # Flip the image horizontally randomly
    vertical_flip=True  # Flip the image vertically randomly
)


train_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory='/Users/pauljenne/Downloads/train',
    x_col="id",
    y_col="label",
    subset="training",
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode="binary",
    target_size=(96, 96)  
)

valid_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory='/Users/pauljenne/Downloads/train',
    x_col="id",
    y_col="label",
    subset="validation",
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode="binary",  
    target_size=(96, 96)
)

test_datagen = ImageDataGenerator(rescale=1./255.)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=testdf,
    directory='/Users/pauljenne/Downloads/test',
    x_col="id",
    y_col=None,
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode=None,
    target_size=(96, 96)
)

train_labels_path = '/Users/pauljenne/Downloads/train_labels.csv'
sample_submission_path = '/Users/pauljenne/Downloads/sample_submission.csv'
sample_submission = pd.read_csv('/Users/pauljenne/Downloads/sample_submission.csv', dtype=str)
# Specify the path to the folder containing the images
images_folder = '/Users/pauljenne/Downloads/train'
# Add a new column to the DataFrame with the full path to the image
traindf['image_path'] = traindf['id'].apply(lambda x: os.path.join(images_folder, f'{x}.tif'))
# Display the first few rows of the dataframes
print("Train Labels:")
print(traindf.head())

print("\nSample Submission:")
print(sample_submission.head())

# ----------------------Beispielbilder----------------------
# Display a few images and their labels of the training set, validation set and test set

# Display a few images and their labels from the training set
train_images = train_generator.next()[0]
train_labels = train_generator.next()[1]
train_class_labels = train_generator.class_indices

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(train_images[i])
    axes[i].set_title(f"Label: {train_labels[i]}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Display a few images and their labels from the validation set
valid_images = valid_generator.next()[0]
valid_labels = valid_generator.next()[1]

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(valid_images[i])
    axes[i].set_title(f"Label: {valid_labels[i]}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Display a few images from the test set
test_images = test_generator.next()

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(test_images[i])
    axes[i].axis('off')

plt.tight_layout()
plt.show()


#----------------------MODEL----------------------
class TransferModel:

    def __init__(self, input_shape: tuple):
        self.input_shape = input_shape
        self.model = self.build_model()

    def build_model(self):
        # Use pre-trained ResNet model
        base_model = ResNet50(
            include_top=False,
            input_shape=self.input_shape,
            weights='imagenet'
        )

        # Allow parameter updates for all layers
        base_model.trainable = True

        # Add a new pooling layer on the original output
        add_to_base = base_model.output
        add_to_base = GlobalAveragePooling2D(data_format='channels_last', name='head_gap')(add_to_base)

        # Add new output layer as head
        new_output = Dense(1, activation='sigmoid', name='head_pred')(add_to_base)  # Assuming binary classification

        # Define model
        model = Model(base_model.input, new_output)

        return model
    
    def train(self,
              train_generator,
              epochs: int,
              valid_generator=None,
              class_weights=None):

        # Define early stopping as callback
        early_stopping = EarlyStopping(monitor='val_loss',
                                       min_delta=0,
                                       patience=12,
                                       restore_best_weights=True)

        callbacks = [early_stopping]

        # Fitting
        self.history = self.model.fit(train_generator,
                                      epochs=epochs,
                                      validation_data=valid_generator,
                                      callbacks=callbacks,
                                      class_weight=class_weights)

        return self.history
    

    def compile_model(self, **kwargs):
        self.model.compile(**kwargs)

    def get_grad_cam(self, img_array, target_size):
        img_array = cv2.resize(img_array, target_size)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array / 255.0   # Rescale the image

        grad_model = Model(inputs=[self.model.input], outputs=[self.model.get_layer('head_gap').output, self.model.output])
        
        with tf.GradientTape() as tape:
            conv_outputs, predictions = grad_model(img_array)
            label_idx = np.argmax(predictions[0])
        
        output = conv_outputs[0]
        grads = tape.gradient(predictions[0][label_idx], conv_outputs)[0]

        # Guided Backprop
        gate_f = tf.cast(output > 0, 'float32')
        gate_r = tf.cast(grads > 0, 'float32')
        guided_grads = gate_f * gate_r * grads

        # Average weight of filters
        weights = tf.reduce_mean(guided_grads, axis=(0, 1))

        # Class activation map (CAM)
        cam = np.zeros(output.shape[0:2], dtype=np.float32)
        for i, w in enumerate(weights):
            cam += w * output[:, :, i]

        # Rescale to original image size and min-max scale
        cam = cv2.resize(cam.numpy(), (target_size[1], target_size[0]))
        cam = np.maximum(cam, 0)
        heatmap = (cam - cam.min()) / (cam.max() - cam.min())

        return heatmap


# Example usage
input_shape = (96, 96, 3)
transfer_model = TransferModel(input_shape)
transfer_model.compile_model(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ----------------------TRAINING----------------------
# Calculate steps per epoch and validation steps
steps_per_epoch = len(train_generator)
validation_steps = len(valid_generator)

# Train the model using your data generators
history = transfer_model.train(train_generator, epochs=25, valid_generator=valid_generator)

# ----------------------EVALUATION----------------------
plt.figure(figsize=(12, 6))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')

# Display the ROC-AUC values
train_predictions = transfer_model.model.predict(train_generator)
valid_predictions = transfer_model.model.predict(valid_generator)

train_roc_auc = roc_auc_score(train_generator.classes, train_predictions)
valid_roc_auc = roc_auc_score(valid_generator.classes, valid_predictions)

print(f'Train ROC-AUC: {train_roc_auc:.4f}')
print(f'Validation ROC-AUC: {valid_roc_auc:.4f}')

plt.show()

# ----------------------GRAD-CAM----------------------
num_samples = 6
sample_images = valid_images[:num_samples]  # Change this to the desired number of samples

plt.figure(figsize=(15, 10))

for i in range(num_samples):
    plt.subplot(2, 3, i+1)
    sample_image = sample_images[i]
    heatmap = transfer_model.get_grad_cam(sample_image, target_size=(96, 96))

    # Display the original image with the heatmap
    plt.imshow(sample_image)
    plt.imshow(heatmap, alpha=0.6, cmap='jet')
    plt.title(f'Sample {i+1}')
    plt.axis('off')

plt.tight_layout()
plt.show()
