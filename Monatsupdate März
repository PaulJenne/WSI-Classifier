import tensorflow as tf
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D
from tensorflow.keras import regularizers, optimizers
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, Callback
from tensorflow.keras.preprocessing.image import img_to_array, load_img

from keras_radam import RAdam
from tensorflow.keras import backend as K

# ----------------------DATEN----------------------
def append_ext(fn):
    return fn + ".tif"  # Bildformat ist .tif

# Einlesen der csv-Dateien als String
traindf = pd.read_csv('/Users/pauljenne/Downloads/train_labels.csv', dtype=str)
testdf = pd.read_csv('/Users/pauljenne/Downloads/sample_submission.csv', dtype=str)

# AnhÃ¤ngen der Dateiendung an die ID
traindf["id"] = traindf["id"].apply(append_ext)
testdf["id"] = testdf["id"].apply(append_ext)

# ----------------------DATENGENERATOR----------------------
# ImageDataGenerator with rescaling and validation split (25% of the data will go to the validation set)
datagen = ImageDataGenerator(
    rescale=1./255.,
    validation_split=0.25,
    rotation_range=20,  # Rotate the image randomly within the range of -20 to +20 degrees
    width_shift_range=0.1,  # Shift the width of the image randomly within the range of -0.1 to +0.1
    height_shift_range=0.1,  # Shift the height of the image randomly within the range of -0.1 to +0.1
    shear_range=0.2,  # Apply shear transformation randomly within the range of -0.2 to +0.2
    zoom_range=0.2,  # Zoom the image randomly within the range of 0.8 to 1.2
    horizontal_flip=True,  # Flip the image horizontally randomly
    vertical_flip=True  # Flip the image vertically randomly
)


train_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory='/Users/pauljenne/Downloads/train',
    x_col="id",
    y_col="label",
    subset="training",
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode="binary",
    target_size=(96, 96)  
)

valid_generator = datagen.flow_from_dataframe(
    dataframe=traindf,
    directory='/Users/pauljenne/Downloads/train',
    x_col="id",
    y_col="label",
    subset="validation",
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode="binary",  
    target_size=(96, 96)
)

test_datagen = ImageDataGenerator(rescale=1./255.)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=testdf,
    directory='/Users/pauljenne/Downloads/test',
    x_col="id",
    y_col=None,
    batch_size=32,
    seed=42,
    shuffle=False,
    class_mode=None,
    target_size=(96, 96)
)

train_labels_path = '/Users/pauljenne/Downloads/train_labels.csv'
sample_submission_path = '/Users/pauljenne/Downloads/sample_submission.csv'
sample_submission = pd.read_csv('/Users/pauljenne/Downloads/sample_submission.csv', dtype=str)
# Specify the path to the folder containing the images
images_folder = '/Users/pauljenne/Downloads/train'
# Add a new column to the DataFrame with the full path to the image
traindf['image_path'] = traindf['id'].apply(lambda x: os.path.join(images_folder, f'{x}.tif'))
# Display the first few rows of the dataframes
print("Train Labels:")
print(traindf.head())

print("\nSample Submission:")
print(sample_submission.head())

# ----------------------Beispielbilder----------------------
# Display a few images and their labels of the training set, validation set and test set

# Display a few images and their labels from the training set
train_images = train_generator.next()[0]
train_labels = train_generator.next()[1]
train_class_labels = train_generator.class_indices

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(train_images[i])
    axes[i].set_title(f"Label: {train_labels[i]}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Display a few images and their labels from the training set
train_batch = train_generator.next()
train_images = train_batch[0]
train_labels = train_batch[1]

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(train_images[i])
    axes[i].set_title(f"Label: {train_labels[i]}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Display a few images and their labels from the validation set
valid_batch = valid_generator.next()
valid_images = valid_batch[0]
valid_labels = valid_batch[1]

fig, axes = plt.subplots(2, 2, figsize=(10, 10))
axes = axes.ravel()

for i in range(4):
    axes[i].imshow(valid_images[i])
    axes[i].set_title(f"Label: {valid_labels[i]}")
    axes[i].axis('off')

plt.tight_layout()
plt.show()


#----------------------MODEL----------------------
class CyclicLR(Callback):
    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular', gamma=1., scale_fn=None, scale_mode='cycle'):
        super(CyclicLR, self).__init__()

        self.base_lr = base_lr
        self.max_lr = max_lr
        self.step_size = step_size
        self.mode = mode
        self.gamma = gamma
        self.scale_fn = scale_fn
        self.scale_mode = scale_mode
        self.clr_iterations = 0.
        self.trn_iterations = 0.
        self.history = {}

        if self.scale_fn is None:
            if self.mode == 'triangular':
                self.scale_fn = lambda x: 1.
                self.scale_mode = 'cycle'
            elif self.mode == 'triangular2':
                self.scale_fn = lambda x: 1 / (2.**(x - 1))
                self.scale_mode = 'cycle'
            elif self.mode == 'exp_range':
                self.scale_fn = lambda x: gamma**(x)
                self.scale_mode = 'iterations'

    def clr(self):
        if self.scale_mode == 'cycle':
            return self.base_lr + (self.clr_iterations % self.step_size) / self.step_size * (self.max_lr - self.base_lr)
        else:
            return self.base_lr + (1 + np.sin(np.pi * (self.clr_iterations % self.step_size) / self.step_size)) * 0.5 * (self.max_lr - self.base_lr)

    def on_train_begin(self, logs={}):
        logs = logs or {}

        if self.clr_iterations == 0:
            K.set_value(self.model.optimizer.lr, self.base_lr)
        else:
            K.set_value(self.model.optimizer.lr, self.clr())

    def on_batch_end(self, epoch, logs=None):

        logs = logs or {}
        self.trn_iterations += 1
        self.clr_iterations += 1

        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))
        self.history.setdefault('iterations', []).append(self.trn_iterations)

        for k, v in logs.items():
            self.history.setdefault(k, []).append(v)

        K.set_value(self.model.optimizer.lr, self.clr())



class TransferModel:

    def __init__(self, input_shape: tuple):
        self.input_shape = input_shape
        self.model = self.build_model()

    def build_model(self):
        # Use pre-trained ResNet model
        base_model = ResNet50(
            include_top=False,
            input_shape=self.input_shape,
            weights='imagenet'
        )

        # Allow parameter updates for all layers
        base_model.trainable = True

        # Add a new pooling layer on the original output
        add_to_base = base_model.output
        add_to_base = GlobalAveragePooling2D(data_format='channels_last', name='head_gap')(add_to_base)

        # Add new output layer as head
        new_output = Dense(1, activation='sigmoid', name='head_pred')(add_to_base)  # Assuming binary classification

        # Define model
        model = Model(base_model.input, new_output)

        return model
    
    def train(self,
              train_generator,
              epochs: int,
              valid_generator=None,
              class_weights=None):

        clr = CyclicLR(base_lr=1e-6, max_lr=1e-3, step_size=8 * (len(train_generator) + len(valid_generator)))

        # Define early stopping as callback
        early_stopping = EarlyStopping(monitor='val_loss',
                                       min_delta=0,
                                       patience=12,
                                       restore_best_weights=True)

        callbacks = [early_stopping, clr]

        # Fitting
        self.history = self.model.fit(train_generator,
                                      epochs=epochs,
                                      validation_data=valid_generator,
                                      callbacks=callbacks,
                                      class_weight=class_weights)

        return self.history
    

    def compile_model(self, **kwargs):
        self.model.compile(**kwargs)



    def grad_cam(self, image, layer_name):
        # Convert the image to a tensor
        image_tensor = tf.convert_to_tensor(image)
        image_tensor = tf.expand_dims(image_tensor, axis=0)

        # Get the output of the specified layer
        output = self.model.get_layer(layer_name).output

        # Get the gradient tape
        with tf.GradientTape() as tape:                
            # Forward pass through the model
            model_output = self.model(image_tensor)
            conv_output = model_output  # Assuming the conv_output is the first element in the output
            predictions = model_output  # Assuming the predictions are the second element in the output
            predicted_class = tf.argmax(predictions[0])

        # Calculate the gradients of the predicted class with respect to the output feature map
        grads = tape.gradient(predictions[:, predicted_class], output)
        
        # Compute the guided gradients
        guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads

        # Get the weights of the guided gradients
        weights = tf.reduce_mean(guided_grads, axis=(0, 1))

        # Get the feature map of the specified layer
        feature_map = self.model.get_layer(layer_name).output[0]

        # Create the heatmap
        heatmap = tf.reduce_sum(tf.multiply(weights, feature_map), axis=-1)
        heatmap = np.maximum(heatmap, 0)
        heatmap /= np.max(heatmap)

        # Resize the heatmap to match the original image size
        heatmap = cv2.resize(heatmap.numpy(), (image.shape[1], image.shape[0]))
        heatmap = np.uint8(255 * heatmap)

        # Apply the heatmap to the original image
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        superimposed_img = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)

        return superimposed_img



# Example usage
input_shape = (96, 96, 3)
transfer_model = TransferModel(input_shape)
transfer_model.compile_model(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ----------------------TRAINING----------------------
# Calculate steps per epoch and validation steps
steps_per_epoch = len(train_generator)
validation_steps = len(valid_generator)

# Train the model using your data generators
history = transfer_model.train(train_generator, epochs=15, valid_generator=valid_generator)

# ----------------------EVALUATION----------------------
plt.figure(figsize=(12, 6))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')


# Display the ROC-AUC values
train_predictions = transfer_model.model.predict(train_generator)
valid_predictions = transfer_model.model.predict(valid_generator)

train_roc_auc = roc_auc_score(train_generator.classes, train_predictions)
valid_roc_auc = roc_auc_score(valid_generator.classes, valid_predictions)

print(f'Train ROC-AUC: {train_roc_auc:.4f}')
print(f'Validation ROC-AUC: {valid_roc_auc:.4f}')

# Calculate the false positive rate (1-specificity) and true positive rate (sensitivity)
train_fpr, train_tpr, _ = roc_curve(train_generator.classes, train_predictions)
valid_fpr, valid_tpr, _ = roc_curve(valid_generator.classes, valid_predictions)

# Display the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(train_fpr, train_tpr, label='Train ROC Curve')
plt.plot(valid_fpr, valid_tpr, label='Validation ROC Curve')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()

plt.show()

# ----------------------GRAD-CAM----------------------

class GradCAM:
    def __init__(self, model, class_index, layer_name):
        self.model = model
        self.class_index = class_index
        self.layer_name = layer_name

        # Ensure that the model is built
        self.model.build((None, *model.input_shape[1:]))

    def get_gradients_and_filters(self, image):
        # Convert image to tensor
        image_tensor = tf.convert_to_tensor([image])

        # Get the target output
        with tf.GradientTape() as tape:
            conv_output, predictions = self.model(image_tensor)
            target_output = predictions[:, self.class_index]

        # Get the gradients of the target class with respect to the output feature map
        grads = K.gradients(target_output, conv_output)[0]

        # Get the convolutional filters of the selected layer
        filters = self.model.get_layer(self.layer_name).output

        return tape, conv_output, grads, filters

    def grad_cam(self, image, alpha=0.4):
        tape, conv_output, grads, filters = self.get_gradients_and_filters(image)

        # Calculate the CAM
        cam = tf.reduce_sum(tf.multiply(grads, filters), axis=-1)
        cam = tf.nn.relu(cam)

        # Normalize the CAM
        cam = (cam - tf.reduce_min(cam)) / (tf.reduce_max(cam) - tf.reduce_min(cam) + 1e-10)

        # Resize the CAM to the original image size
        cam = tf.image.resize(cam, (image.shape[1], image.shape[0]))

        # Convert the CAM to NumPy array
        cam = cam.numpy()

        # Combine the CAM with the original image
        heatmap = (255 * cam).astype(np.uint8)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        grad_cam = cv2.addWeighted(image, 0.7, heatmap, 0.3, 0)

        return grad_cam

    def get_gradients_and_filters(self, image):
        # Convert image to tensor
        image_tensor = tf.convert_to_tensor([image])

        # Get the target output
        with tf.GradientTape() as tape:
            conv_output, predictions = self.model(image_tensor)
            target_output = predictions[:, self.class_index]

        # Get the gradients of the target class with respect to the output feature map
        grads = K.gradients(target_output, conv_output)[0]

        # Get the convolutional filters of the selected layer
        filters = self.model.get_layer(self.layer_name).output

        return tape, conv_output, grads, filters


    def grad_cam(self, image, alpha=0.4):
        def grad_cam(self, image, alpha=0.4):
            result = self.get_gradients_and_filters(image)
            print(result)
            tape, conv_output, grads, filters = result

        # Normalize the CAM
        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam) + 1e-10)

        # Resize the CAM to the original image size
        cam = tf.image.resize(cam, (image.shape[1], image.shape[0]))

        # Convert the CAM to NumPy array
        cam = cam.numpy()

        # Combine the CAM with the original image
        heatmap = (255 * cam).astype(np.uint8)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        grad_cam = cv2.addWeighted(image, 0.7, heatmap, 0.3, 0)

        return grad_cam

# Example usage 


def get_gradients_and_filters(self, image):
    # Convert image to tensor
    image_tensor = tf.convert_to_tensor([image])

    # Get the target output
    with tf.GradientTape() as tape:
        conv_output, predictions = self.model(image_tensor)
        target_output = predictions[:, self.class_index]

    # Get the gradients of the target class with respect to the output feature map
    grads = tape.gradient(target_output, conv_output)

    # Get the convolutional filters of the selected layer
    filters = self.model.get_layer(self.layer_name).output

    return tape, conv_output, grads, filters

image_path = "/Users/pauljenne/Downloads/test/0a0e1de0d1bd38eff2942efc13e5e0420597f295.tif"

try:
    image = load_img(image_path, target_size=(96, 96))
    image = img_to_array(image)
except Exception as e:
    print(f"Error loading or processing the image: {e}")
    # Add appropriate error handling or exit the program

grad_cam = GradCAM(model=transfer_model.model, class_index=1, layer_name='conv5_block3_out')

try:
    result = grad_cam.grad_cam(image)
    plt.imshow(result)
    plt.show()
except Exception as e:
    print(f"Error generating GradCAM: {e}")
    # Add appropriate error handling or exit the program

